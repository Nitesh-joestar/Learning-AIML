{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0cde7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4cd37ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a3fd707",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_dataset=datasets.FashionMNIST(root='./data',transform=transform,download=True,train=True)\n",
    "te_dataset=datasets.FashionMNIST(root='./data',transform=transform,download=True,train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "905c957a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(t_dataset,batch_size=128,shuffle=True)\n",
    "test_loader=DataLoader(te_dataset,batch_size=128,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d47c002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e9d3e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c574a773",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=nn.Sequential(\n",
    "    nn.Conv2d(1,32,3),#26x26\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2,2),#13x13\n",
    "    nn.Conv2d(32,64,3),#11x11\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(64,128,3),#9x9\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2,2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(4*4*128,128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128,100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100,10)\n",
    ")\n",
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "514f8a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "criteriorn=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5e6e38e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :1\n",
      "        Accuracy:0.8267\n",
      "Epoch :2\n",
      "        Accuracy:0.8675\n",
      "Epoch :3\n",
      "        Accuracy:0.879\n",
      "Epoch :4\n",
      "        Accuracy:0.8891\n",
      "Epoch :5\n",
      "        Accuracy:0.8993\n",
      "Epoch :6\n",
      "        Accuracy:0.8971\n",
      "Epoch :7\n",
      "        Accuracy:0.907\n",
      "Epoch :8\n",
      "        Accuracy:0.9111\n",
      "Epoch :9\n",
      "        Accuracy:0.913\n",
      "Epoch :10\n",
      "        Accuracy:0.9094\n",
      "Epoch :11\n",
      "        Accuracy:0.9156\n",
      "Epoch :12\n",
      "        Accuracy:0.9128\n",
      "Epoch :13\n",
      "        Accuracy:0.9117\n",
      "Epoch :14\n",
      "        Accuracy:0.9144\n",
      "Epoch :15\n",
      "        Accuracy:0.9176\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m20\u001b[39m):\n\u001b[32m      2\u001b[39m     model.train()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m images,labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[32m      4\u001b[39m         images,labels=images.to(device),labels.to(device)\n\u001b[32m      5\u001b[39m         optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nichu\\.conda\\envs\\jupytorch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28mself\u001b[39m._next_data()\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nichu\\.conda\\envs\\jupytorch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28mself\u001b[39m._dataset_fetcher.fetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nichu\\.conda\\envs\\jupytorch\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28mself\u001b[39m.dataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nichu\\.conda\\envs\\jupytorch\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28mself\u001b[39m.dataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nichu\\.conda\\envs\\jupytorch\\Lib\\site-packages\\torchvision\\datasets\\mnist.py:146\u001b[39m, in \u001b[36mMNIST.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    143\u001b[39m img = Image.fromarray(img.numpy(), mode=\u001b[33m\"\u001b[39m\u001b[33mL\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     img = \u001b[38;5;28mself\u001b[39m.transform(img)\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.target_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    149\u001b[39m     target = \u001b[38;5;28mself\u001b[39m.target_transform(target)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nichu\\.conda\\envs\\jupytorch\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001b[39m, in \u001b[36mToTensor.__call__\u001b[39m\u001b[34m(self, pic)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[32m    130\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    131\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    135\u001b[39m \u001b[33;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[32m    136\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.to_tensor(pic)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nichu\\.conda\\envs\\jupytorch\\Lib\\site-packages\\torchvision\\transforms\\functional.py:176\u001b[39m, in \u001b[36mto_tensor\u001b[39m\u001b[34m(pic)\u001b[39m\n\u001b[32m    174\u001b[39m img = img.permute((\u001b[32m2\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m)).contiguous()\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch.ByteTensor):\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m img.to(dtype=default_float_dtype).div(\u001b[32m255\u001b[39m)\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    for images,labels in train_loader:\n",
    "        images,labels=images.to(device),labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output=model(images)\n",
    "        loss=criteriorn(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    correct,total=0,0\n",
    "    with torch.no_grad():\n",
    "        for images,labels in test_loader:\n",
    "            images,labels=images.to(device),labels.to(device)\n",
    "            output=model(images)\n",
    "            _,predicted=torch.max(output,1)\n",
    "            total+=labels.size(0)\n",
    "            correct+=(predicted==labels).sum().item()\n",
    "    accuracy=correct/total\n",
    "    print(f\"Epoch :{epoch+1}\")\n",
    "    print(f\"        Accuracy:{accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e838b5c5",
   "metadata": {},
   "source": [
    "for lr 0.005 loss was 0.94"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a7b6e6",
   "metadata": {},
   "source": [
    "training stats   \n",
    "Epoch :1  \n",
    "        Accuracy:0.87475  \n",
    "Epoch :2  \n",
    "        Accuracy:0.8773666666666666  \n",
    "Epoch :3  \n",
    "        Accuracy:0.8924833333333333  \n",
    "Epoch :4  \n",
    "        Accuracy:0.8867833333333334  \n",
    "Epoch :5  \n",
    "        Accuracy:0.8959  \n",
    "Epoch :6  \n",
    "        Accuracy:0.9018666666666667  \n",
    "Epoch :7  \n",
    "        Accuracy:0.9035  \n",
    "Epoch :8   \n",
    "        Accuracy:0.90195  \n",
    "Epoch :9  \n",
    "        Accuracy:0.90245  \n",
    "Epoch :10  \n",
    "        Accuracy:0.8995666666666666  \n",
    " \n",
    "  \n",
    "for lr=0.01   \n",
    "  \n",
    "    nn.Conv2d(1,32,3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2,2),\n",
    "    nn.Conv2d(32,64,3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2,2),"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa1f171",
   "metadata": {},
   "source": [
    "Epoch :1\n",
    "        Accuracy:0.8517666666666667\n",
    "Epoch :2\n",
    "        Accuracy:0.87735\n",
    "Epoch :3\n",
    "        Accuracy:0.8887833333333334\n",
    "Epoch :4\n",
    "        Accuracy:0.9008\n",
    "Epoch :5\n",
    "        Accuracy:0.9095666666666666\n",
    "Epoch :6\n",
    "        Accuracy:0.9106166666666666\n",
    "Epoch :7\n",
    "        Accuracy:0.9237166666666666\n",
    "Epoch :8\n",
    "        Accuracy:0.93065\n",
    "Epoch :9\n",
    "        Accuracy:0.9304666666666667\n",
    "Epoch :10\n",
    "        Accuracy:0.94095\n",
    "\n",
    "        same as above but with lr 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0108d75d",
   "metadata": {},
   "source": [
    "Epoch :1\n",
    "        Accuracy:0.84435\n",
    "Epoch :2\n",
    "        Accuracy:0.86725\n",
    "Epoch :3\n",
    "        Accuracy:0.8897166666666667\n",
    "Epoch :4\n",
    "        Accuracy:0.90185\n",
    "Epoch :5\n",
    "        Accuracy:0.9086666666666666\n",
    "Epoch :6\n",
    "        Accuracy:0.9117666666666666\n",
    "Epoch :7\n",
    "        Accuracy:0.9198666666666667\n",
    "Epoch :8\n",
    "        Accuracy:0.9299333333333333\n",
    "Epoch :9\n",
    "        Accuracy:0.9312\n",
    "Epoch :10\n",
    "        Accuracy:0.94025\n",
    "\n",
    "model=nn.Sequential\n",
    "    nn.Conv2d(1,32,3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2,2),\n",
    "    nn.Conv2d(32,64,3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2,2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(5*5*64,128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128,100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100,10)\n",
    "\n",
    "    didnt make a difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230ad46d",
   "metadata": {},
   "source": [
    "Epoch :1\n",
    "        Accuracy:0.8466\n",
    "Epoch :2\n",
    "        Accuracy:0.86905\n",
    "Epoch :3\n",
    "        Accuracy:0.8821333333333333\n",
    "Epoch :4\n",
    "        Accuracy:0.9027833333333334\n",
    "Epoch :5\n",
    "        Accuracy:0.9159833333333334\n",
    "Epoch :6\n",
    "        Accuracy:0.9223333333333333\n",
    "Epoch :7\n",
    "        Accuracy:0.9322666666666667\n",
    "Epoch :8\n",
    "        Accuracy:0.9347333333333333\n",
    "Epoch :9\n",
    "        Accuracy:0.9391\n",
    "Epoch :10\n",
    "        Accuracy:0.94515\n",
    "\n",
    "        model=nn.Sequential(\n",
    "    nn.Conv2d(1,32,3),#26x26\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2,2),#13x13\n",
    "    nn.Conv2d(32,64,3),#11x11\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(64,128,3),#9x9\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2,2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(4*4*128,128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128,10)\n",
    ")still didnt make a diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5e1027",
   "metadata": {},
   "source": [
    "Epoch :1\n",
    "        Accuracy:0.82005\n",
    "Epoch :2\n",
    "        Accuracy:0.8590166666666667\n",
    "Epoch :3\n",
    "        Accuracy:0.88315\n",
    "Epoch :4\n",
    "        Accuracy:0.8997166666666667\n",
    "Epoch :5\n",
    "        Accuracy:0.9072333333333333\n",
    "Epoch :6\n",
    "        Accuracy:0.9166\n",
    "Epoch :7\n",
    "        Accuracy:0.9197333333333333\n",
    "Epoch :8\n",
    "        Accuracy:0.92215\n",
    "Epoch :9\n",
    "        Accuracy:0.9182166666666667\n",
    "Epoch :10\n",
    "        Accuracy:0.9394166666666667\n",
    "\n",
    "        model=nn.Sequential(\n",
    "    nn.Conv2d(1,32,3),#26x26\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2,2),#13x13\n",
    "    nn.Conv2d(32,64,3),#11x11\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(64,128,3),#9x9\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2,2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(4*4*128,128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128,100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100,10)\n",
    ")\n",
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142f1607",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupytorch",
   "language": "python",
   "name": "jupytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
