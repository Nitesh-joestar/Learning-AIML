{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "746f2344",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9517ff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,channels,features_d):\n",
    "        super(Discriminator,self).__init__()\n",
    "        self.disc=nn.Sequential(\n",
    "            nn.Conv2d(channels,features_d,4,2,1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            self._block(features_d,features_d*2,4,2,1),\n",
    "            self._block(features_d*2,features_d*4,4,2,1),\n",
    "            self._block(features_d*4,features_d*8,4,2,1),\n",
    "            nn.Conv2d(features_d*8,1,4,2,0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def _block(self,in_channels,out_channels,kernel_size,stride,padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels,out_channels,kernel_size,stride,padding,bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.disc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3e22ca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def _block(self,in_channels,out_channels,kernel_size,stride,padding):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels,out_channels,kernel_size,stride,padding,bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "    def __init__(self,z_dim,img_channels,features_g):\n",
    "        super(Generator,self).__init__()\n",
    "        self.gen=nn.Sequential(\n",
    "            self._block(z_dim,features_g*8,4,1,0),\n",
    "            self._block(features_g*8,features_g*4,4,2,1),\n",
    "            self._block(features_g*4,features_g*2,4,2,1),\n",
    "            self._block(features_g*2,features_g*1,4,2,1),\n",
    "            nn.ConvTranspose2d(features_g,img_channels,4,2,1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.gen(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e4eba49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m,(nn.ConvTranspose2d,nn.Conv2d,nn.BatchNorm2d)):\n",
    "            nn.init.normal_(m.weight.data,0.0,0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8fe109b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    N,in_channels,H,W=8,3,64,64\n",
    "    z_dim=100\n",
    "    x=torch.randn((N,in_channels,H,W))\n",
    "    disc=Discriminator(in_channels,8)\n",
    "    initialize_weights(disc)\n",
    "    assert disc(x).shape==(N,1,1,1 )\n",
    "    gen=Generator(z_dim,in_channels,8)\n",
    "    initialize_weights(gen)\n",
    "    z=torch.randn((N,z_dim,1,1))\n",
    "    assert gen(z).shape==(N,in_channels,H,W)\n",
    "    print(\"Success\")\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2345cf8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9b5ca193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0002"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr=2e-4\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d641bf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size=64\n",
    "batch_size=64\n",
    "z_dim=256\n",
    "img_channels=3\n",
    "features_d=64\n",
    "features_g=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4dd46827",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.Resize((img_size,img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5 for _ in range(img_channels)],[0.5 for _ in range(img_channels)])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "158871cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=datasets.ImageFolder(root='data/celeba/',transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8a0b2ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=DataLoader(dataset,batch_size=batch_size,shuffle=True,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8306b1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen=Generator(z_dim=z_dim,img_channels=img_channels,features_g=features_g).to(device)\n",
    "disc=Discriminator(channels=img_channels,features_d=features_d).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "60a9d60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_weights(gen)\n",
    "initialize_weights(disc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "aa72f8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_gen=optim.Adam(gen.parameters(),lr=lr,betas=(0.5,0.999))\n",
    "opt_disc=optim.Adam(disc.parameters(),lr=lr,betas=(0.5,0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7d2c7591",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5e303080",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_noise=torch.randn((32,z_dim,1,1)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f7a786ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.8216]],\n",
       "\n",
       "         [[ 1.4291]],\n",
       "\n",
       "         [[-0.1752]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.3314]],\n",
       "\n",
       "         [[-0.6916]],\n",
       "\n",
       "         [[-0.4866]]],\n",
       "\n",
       "\n",
       "        [[[-0.1484]],\n",
       "\n",
       "         [[-0.0366]],\n",
       "\n",
       "         [[-0.3422]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.3145]],\n",
       "\n",
       "         [[ 1.5720]],\n",
       "\n",
       "         [[ 1.0168]]],\n",
       "\n",
       "\n",
       "        [[[-0.1716]],\n",
       "\n",
       "         [[-0.4857]],\n",
       "\n",
       "         [[-0.4893]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.7237]],\n",
       "\n",
       "         [[-0.5232]],\n",
       "\n",
       "         [[ 0.6144]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-0.4139]],\n",
       "\n",
       "         [[-0.2013]],\n",
       "\n",
       "         [[ 1.1573]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.2161]],\n",
       "\n",
       "         [[-0.8906]],\n",
       "\n",
       "         [[-1.4038]]],\n",
       "\n",
       "\n",
       "        [[[-0.3960]],\n",
       "\n",
       "         [[ 0.6921]],\n",
       "\n",
       "         [[-1.7239]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.4450]],\n",
       "\n",
       "         [[-1.1471]],\n",
       "\n",
       "         [[ 0.9505]]],\n",
       "\n",
       "\n",
       "        [[[ 1.2643]],\n",
       "\n",
       "         [[ 0.7105]],\n",
       "\n",
       "         [[-0.2253]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.2549]],\n",
       "\n",
       "         [[ 0.6981]],\n",
       "\n",
       "         [[-0.0171]]]], device='cuda:0')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cbf65297",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_real=SummaryWriter(f\"runs/RDCGAN/real\")\n",
    "writer_fake=SummaryWriter(f\"runs/RDCGAN/fake\")\n",
    "step=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2cc36ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0\n",
      "Loss Generator:0.8140408992767334\n",
      "Loss Discriminator:0.6883387565612793\n",
      "Epoch:0\n",
      "Loss Generator:2.3096766471862793\n",
      "Loss Discriminator:0.3255464732646942\n",
      "Epoch:0\n",
      "Loss Generator:2.101498603820801\n",
      "Loss Discriminator:0.3811744749546051\n",
      "Epoch:0\n",
      "Loss Generator:1.3203067779541016\n",
      "Loss Discriminator:0.5154972076416016\n",
      "Epoch:0\n",
      "Loss Generator:1.7277944087982178\n",
      "Loss Discriminator:0.544561505317688\n",
      "Epoch:0\n",
      "Loss Generator:1.6224596500396729\n",
      "Loss Discriminator:0.4926971197128296\n",
      "Epoch:0\n",
      "Loss Generator:1.4252588748931885\n",
      "Loss Discriminator:0.5340104103088379\n",
      "Epoch:0\n",
      "Loss Generator:1.264326572418213\n",
      "Loss Discriminator:0.5867581367492676\n",
      "Epoch:0\n",
      "Loss Generator:1.2286951541900635\n",
      "Loss Discriminator:0.6103821396827698\n",
      "Epoch:0\n",
      "Loss Generator:1.3118054866790771\n",
      "Loss Discriminator:0.6634307503700256\n",
      "Epoch:0\n",
      "Loss Generator:1.9377597570419312\n",
      "Loss Discriminator:0.4748638868331909\n",
      "Epoch:0\n",
      "Loss Generator:1.59598970413208\n",
      "Loss Discriminator:0.49841269850730896\n",
      "Epoch:0\n",
      "Loss Generator:1.9941774606704712\n",
      "Loss Discriminator:0.493147075176239\n",
      "Epoch:0\n",
      "Loss Generator:1.5473917722702026\n",
      "Loss Discriminator:0.5313185453414917\n",
      "Epoch:0\n",
      "Loss Generator:1.5799256563186646\n",
      "Loss Discriminator:0.512409508228302\n",
      "Epoch:0\n",
      "Loss Generator:2.4200291633605957\n",
      "Loss Discriminator:0.388343870639801\n",
      "Epoch:0\n",
      "Loss Generator:2.2250468730926514\n",
      "Loss Discriminator:0.47572189569473267\n",
      "Epoch:0\n",
      "Loss Generator:1.7569118738174438\n",
      "Loss Discriminator:0.4593539834022522\n",
      "Epoch:0\n",
      "Loss Generator:1.712435245513916\n",
      "Loss Discriminator:0.45523977279663086\n",
      "Epoch:0\n",
      "Loss Generator:1.3774389028549194\n",
      "Loss Discriminator:0.5228514671325684\n",
      "Epoch:0\n",
      "Loss Generator:2.442938804626465\n",
      "Loss Discriminator:0.4957536458969116\n",
      "Epoch:0\n",
      "Loss Generator:2.9858791828155518\n",
      "Loss Discriminator:0.42120885848999023\n",
      "Epoch:0\n",
      "Loss Generator:3.3493456840515137\n",
      "Loss Discriminator:0.5108251571655273\n",
      "Epoch:0\n",
      "Loss Generator:1.939127802848816\n",
      "Loss Discriminator:0.4471553564071655\n",
      "Epoch:0\n",
      "Loss Generator:1.4929208755493164\n",
      "Loss Discriminator:0.550125777721405\n",
      "Epoch:0\n",
      "Loss Generator:2.0643887519836426\n",
      "Loss Discriminator:0.40141427516937256\n",
      "Epoch:0\n",
      "Loss Generator:1.5733860731124878\n",
      "Loss Discriminator:0.458008736371994\n",
      "Epoch:0\n",
      "Loss Generator:1.4018304347991943\n",
      "Loss Discriminator:0.481838196516037\n",
      "Epoch:0\n",
      "Loss Generator:2.875242233276367\n",
      "Loss Discriminator:0.42244845628738403\n",
      "Epoch:0\n",
      "Loss Generator:1.8110612630844116\n",
      "Loss Discriminator:0.4136171042919159\n",
      "Epoch:0\n",
      "Loss Generator:2.8170204162597656\n",
      "Loss Discriminator:0.42488524317741394\n",
      "Epoch:0\n",
      "Loss Generator:2.419154644012451\n",
      "Loss Discriminator:0.37817689776420593\n",
      "Epoch:1\n",
      "Loss Generator:1.2618463039398193\n",
      "Loss Discriminator:0.4907311201095581\n",
      "Epoch:1\n",
      "Loss Generator:2.3124775886535645\n",
      "Loss Discriminator:0.42300963401794434\n",
      "Epoch:1\n",
      "Loss Generator:3.2772278785705566\n",
      "Loss Discriminator:0.5083050727844238\n",
      "Epoch:1\n",
      "Loss Generator:1.900888204574585\n",
      "Loss Discriminator:0.41066503524780273\n",
      "Epoch:1\n",
      "Loss Generator:2.1896157264709473\n",
      "Loss Discriminator:0.43235594034194946\n",
      "Epoch:1\n",
      "Loss Generator:2.9036149978637695\n",
      "Loss Discriminator:0.5290358066558838\n",
      "Epoch:1\n",
      "Loss Generator:2.0612874031066895\n",
      "Loss Discriminator:0.4284490942955017\n",
      "Epoch:1\n",
      "Loss Generator:1.761053204536438\n",
      "Loss Discriminator:0.43035605549812317\n",
      "Epoch:1\n",
      "Loss Generator:3.654533863067627\n",
      "Loss Discriminator:0.4934258460998535\n",
      "Epoch:1\n",
      "Loss Generator:1.4789817333221436\n",
      "Loss Discriminator:0.42251598834991455\n",
      "Epoch:1\n",
      "Loss Generator:1.0823860168457031\n",
      "Loss Discriminator:0.4937050938606262\n",
      "Epoch:1\n",
      "Loss Generator:1.784956932067871\n",
      "Loss Discriminator:0.40946364402770996\n",
      "Epoch:1\n",
      "Loss Generator:2.1224942207336426\n",
      "Loss Discriminator:0.4159487783908844\n",
      "Epoch:1\n",
      "Loss Generator:2.9608891010284424\n",
      "Loss Discriminator:0.4497101306915283\n",
      "Epoch:1\n",
      "Loss Generator:3.3317251205444336\n",
      "Loss Discriminator:0.7942019701004028\n",
      "Epoch:1\n",
      "Loss Generator:1.6260261535644531\n",
      "Loss Discriminator:0.4844397306442261\n",
      "Epoch:1\n",
      "Loss Generator:1.3188955783843994\n",
      "Loss Discriminator:0.44864627718925476\n",
      "Epoch:1\n",
      "Loss Generator:1.8239954710006714\n",
      "Loss Discriminator:0.48328065872192383\n",
      "Epoch:1\n",
      "Loss Generator:2.6814944744110107\n",
      "Loss Discriminator:0.4190412163734436\n",
      "Epoch:1\n",
      "Loss Generator:1.3493058681488037\n",
      "Loss Discriminator:0.45764485001564026\n",
      "Epoch:1\n",
      "Loss Generator:1.6819283962249756\n",
      "Loss Discriminator:0.4778788089752197\n",
      "Epoch:1\n",
      "Loss Generator:1.7415409088134766\n",
      "Loss Discriminator:0.417440801858902\n",
      "Epoch:1\n",
      "Loss Generator:1.52315354347229\n",
      "Loss Discriminator:0.43210330605506897\n",
      "Epoch:1\n",
      "Loss Generator:2.640770435333252\n",
      "Loss Discriminator:0.5091354846954346\n",
      "Epoch:1\n",
      "Loss Generator:1.8049004077911377\n",
      "Loss Discriminator:0.39116334915161133\n",
      "Epoch:1\n",
      "Loss Generator:3.0141072273254395\n",
      "Loss Discriminator:0.6214687824249268\n",
      "Epoch:1\n",
      "Loss Generator:2.024980068206787\n",
      "Loss Discriminator:0.413409560918808\n",
      "Epoch:1\n",
      "Loss Generator:2.827713966369629\n",
      "Loss Discriminator:0.42745617032051086\n",
      "Epoch:1\n",
      "Loss Generator:1.724975824356079\n",
      "Loss Discriminator:0.41460341215133667\n",
      "Epoch:1\n",
      "Loss Generator:2.4874048233032227\n",
      "Loss Discriminator:0.47491127252578735\n",
      "Epoch:1\n",
      "Loss Generator:1.1733579635620117\n",
      "Loss Discriminator:0.5087679624557495\n",
      "Epoch:1\n",
      "Loss Generator:2.034428596496582\n",
      "Loss Discriminator:0.36523088812828064\n",
      "Epoch:2\n",
      "Loss Generator:1.6978636980056763\n",
      "Loss Discriminator:0.443818062543869\n",
      "Epoch:2\n",
      "Loss Generator:1.944001317024231\n",
      "Loss Discriminator:0.4328365921974182\n",
      "Epoch:2\n",
      "Loss Generator:3.149325370788574\n",
      "Loss Discriminator:0.4368647336959839\n",
      "Epoch:2\n",
      "Loss Generator:0.9404556155204773\n",
      "Loss Discriminator:0.6330665946006775\n",
      "Epoch:2\n",
      "Loss Generator:1.5746707916259766\n",
      "Loss Discriminator:0.4560738205909729\n",
      "Epoch:2\n",
      "Loss Generator:1.0320255756378174\n",
      "Loss Discriminator:0.6523244380950928\n",
      "Epoch:2\n",
      "Loss Generator:1.6217119693756104\n",
      "Loss Discriminator:0.4237663745880127\n",
      "Epoch:2\n",
      "Loss Generator:2.2149710655212402\n",
      "Loss Discriminator:0.35686635971069336\n",
      "Epoch:2\n",
      "Loss Generator:3.423612117767334\n",
      "Loss Discriminator:0.5925183296203613\n",
      "Epoch:2\n",
      "Loss Generator:2.273951768875122\n",
      "Loss Discriminator:0.3934830129146576\n",
      "Epoch:2\n",
      "Loss Generator:2.44710636138916\n",
      "Loss Discriminator:0.4903635084629059\n",
      "Epoch:2\n",
      "Loss Generator:1.8593003749847412\n",
      "Loss Discriminator:0.4126729965209961\n",
      "Epoch:2\n",
      "Loss Generator:2.1872878074645996\n",
      "Loss Discriminator:0.3680916726589203\n",
      "Epoch:2\n",
      "Loss Generator:2.0862855911254883\n",
      "Loss Discriminator:0.443963885307312\n",
      "Epoch:2\n",
      "Loss Generator:1.879359483718872\n",
      "Loss Discriminator:0.39494019746780396\n",
      "Epoch:2\n",
      "Loss Generator:2.680309295654297\n",
      "Loss Discriminator:0.5491275787353516\n",
      "Epoch:2\n",
      "Loss Generator:2.355475902557373\n",
      "Loss Discriminator:0.4776694178581238\n",
      "Epoch:2\n",
      "Loss Generator:1.782609462738037\n",
      "Loss Discriminator:0.4072344899177551\n",
      "Epoch:2\n",
      "Loss Generator:2.9886555671691895\n",
      "Loss Discriminator:0.552236795425415\n",
      "Epoch:2\n",
      "Loss Generator:1.623570442199707\n",
      "Loss Discriminator:0.4456172585487366\n",
      "Epoch:2\n",
      "Loss Generator:1.3096442222595215\n",
      "Loss Discriminator:0.4856378436088562\n",
      "Epoch:2\n",
      "Loss Generator:1.670365333557129\n",
      "Loss Discriminator:0.39988642930984497\n",
      "Epoch:2\n",
      "Loss Generator:1.5041919946670532\n",
      "Loss Discriminator:0.4581593871116638\n",
      "Epoch:2\n",
      "Loss Generator:1.5885595083236694\n",
      "Loss Discriminator:0.4207192063331604\n",
      "Epoch:2\n",
      "Loss Generator:1.7130110263824463\n",
      "Loss Discriminator:0.44756630063056946\n",
      "Epoch:2\n",
      "Loss Generator:2.473917245864868\n",
      "Loss Discriminator:0.412304550409317\n",
      "Epoch:2\n",
      "Loss Generator:2.281773090362549\n",
      "Loss Discriminator:0.43422645330429077\n",
      "Epoch:2\n",
      "Loss Generator:2.459688663482666\n",
      "Loss Discriminator:0.44961148500442505\n",
      "Epoch:2\n",
      "Loss Generator:1.5919708013534546\n",
      "Loss Discriminator:0.4521891176700592\n",
      "Epoch:2\n",
      "Loss Generator:1.4947749376296997\n",
      "Loss Discriminator:0.39883044362068176\n",
      "Epoch:2\n",
      "Loss Generator:1.5930795669555664\n",
      "Loss Discriminator:0.3827597200870514\n",
      "Epoch:2\n",
      "Loss Generator:1.5267503261566162\n",
      "Loss Discriminator:0.41905924677848816\n",
      "Epoch:3\n",
      "Loss Generator:2.941354751586914\n",
      "Loss Discriminator:0.5292078256607056\n",
      "Epoch:3\n",
      "Loss Generator:1.6909432411193848\n",
      "Loss Discriminator:0.42272278666496277\n",
      "Epoch:3\n",
      "Loss Generator:2.137876272201538\n",
      "Loss Discriminator:0.3833659589290619\n",
      "Epoch:3\n",
      "Loss Generator:1.205322027206421\n",
      "Loss Discriminator:0.4586745500564575\n",
      "Epoch:3\n",
      "Loss Generator:1.738581895828247\n",
      "Loss Discriminator:0.41935890913009644\n",
      "Epoch:3\n",
      "Loss Generator:1.9244095087051392\n",
      "Loss Discriminator:0.40927404165267944\n",
      "Epoch:3\n",
      "Loss Generator:3.0561413764953613\n",
      "Loss Discriminator:0.44595110416412354\n",
      "Epoch:3\n",
      "Loss Generator:2.4356350898742676\n",
      "Loss Discriminator:0.47254377603530884\n",
      "Epoch:3\n",
      "Loss Generator:1.6610267162322998\n",
      "Loss Discriminator:0.45420530438423157\n",
      "Epoch:3\n",
      "Loss Generator:0.9389550685882568\n",
      "Loss Discriminator:0.7624421119689941\n",
      "Epoch:3\n",
      "Loss Generator:1.5055513381958008\n",
      "Loss Discriminator:0.47981128096580505\n",
      "Epoch:3\n",
      "Loss Generator:2.7343902587890625\n",
      "Loss Discriminator:0.5077348947525024\n",
      "Epoch:3\n",
      "Loss Generator:3.336998701095581\n",
      "Loss Discriminator:0.6354203224182129\n",
      "Epoch:3\n",
      "Loss Generator:1.09688401222229\n",
      "Loss Discriminator:0.5146580934524536\n",
      "Epoch:3\n",
      "Loss Generator:1.474926233291626\n",
      "Loss Discriminator:0.4583323895931244\n",
      "Epoch:3\n",
      "Loss Generator:2.689103603363037\n",
      "Loss Discriminator:0.44305509328842163\n",
      "Epoch:3\n",
      "Loss Generator:1.6075148582458496\n",
      "Loss Discriminator:0.3772103190422058\n",
      "Epoch:3\n",
      "Loss Generator:1.929532766342163\n",
      "Loss Discriminator:0.40752530097961426\n",
      "Epoch:3\n",
      "Loss Generator:1.3320331573486328\n",
      "Loss Discriminator:0.4224598705768585\n",
      "Epoch:3\n",
      "Loss Generator:1.676387071609497\n",
      "Loss Discriminator:0.4032677412033081\n",
      "Epoch:3\n",
      "Loss Generator:2.9452643394470215\n",
      "Loss Discriminator:0.520742654800415\n",
      "Epoch:3\n",
      "Loss Generator:1.9033176898956299\n",
      "Loss Discriminator:0.41090336441993713\n",
      "Epoch:3\n",
      "Loss Generator:3.878375291824341\n",
      "Loss Discriminator:0.4617908298969269\n",
      "Epoch:3\n",
      "Loss Generator:2.6670982837677\n",
      "Loss Discriminator:0.38582801818847656\n",
      "Epoch:3\n",
      "Loss Generator:2.795435905456543\n",
      "Loss Discriminator:0.47823840379714966\n",
      "Epoch:3\n",
      "Loss Generator:1.544726014137268\n",
      "Loss Discriminator:0.45157280564308167\n",
      "Epoch:3\n",
      "Loss Generator:3.222442626953125\n",
      "Loss Discriminator:0.650801420211792\n",
      "Epoch:3\n",
      "Loss Generator:1.9264262914657593\n",
      "Loss Discriminator:0.37609803676605225\n",
      "Epoch:3\n",
      "Loss Generator:3.5142059326171875\n",
      "Loss Discriminator:0.6474603414535522\n",
      "Epoch:3\n",
      "Loss Generator:3.8119399547576904\n",
      "Loss Discriminator:0.46992096304893494\n",
      "Epoch:3\n",
      "Loss Generator:1.3817394971847534\n",
      "Loss Discriminator:0.48226237297058105\n",
      "Epoch:3\n",
      "Loss Generator:1.5802031755447388\n",
      "Loss Discriminator:0.40536266565322876\n",
      "Epoch:4\n",
      "Loss Generator:3.087109088897705\n",
      "Loss Discriminator:0.4319913387298584\n",
      "Epoch:4\n",
      "Loss Generator:1.6406548023223877\n",
      "Loss Discriminator:0.37017661333084106\n",
      "Epoch:4\n",
      "Loss Generator:1.5638539791107178\n",
      "Loss Discriminator:0.392936110496521\n",
      "Epoch:4\n",
      "Loss Generator:1.9505155086517334\n",
      "Loss Discriminator:0.5164426565170288\n",
      "Epoch:4\n",
      "Loss Generator:2.5497822761535645\n",
      "Loss Discriminator:0.4001516103744507\n",
      "Epoch:4\n",
      "Loss Generator:1.7179595232009888\n",
      "Loss Discriminator:0.4464338719844818\n",
      "Epoch:4\n",
      "Loss Generator:2.290621757507324\n",
      "Loss Discriminator:0.38559257984161377\n",
      "Epoch:4\n",
      "Loss Generator:1.9747893810272217\n",
      "Loss Discriminator:0.3950388729572296\n",
      "Epoch:4\n",
      "Loss Generator:2.182222843170166\n",
      "Loss Discriminator:0.36997222900390625\n",
      "Epoch:4\n",
      "Loss Generator:3.894547700881958\n",
      "Loss Discriminator:0.6108734011650085\n",
      "Epoch:4\n",
      "Loss Generator:2.5763773918151855\n",
      "Loss Discriminator:0.3959505558013916\n",
      "Epoch:4\n",
      "Loss Generator:3.181778907775879\n",
      "Loss Discriminator:0.4463379383087158\n",
      "Epoch:4\n",
      "Loss Generator:2.4168901443481445\n",
      "Loss Discriminator:0.4189675450325012\n",
      "Epoch:4\n",
      "Loss Generator:2.4320569038391113\n",
      "Loss Discriminator:0.3743034601211548\n",
      "Epoch:4\n",
      "Loss Generator:2.1184911727905273\n",
      "Loss Discriminator:0.381622314453125\n",
      "Epoch:4\n",
      "Loss Generator:1.8335964679718018\n",
      "Loss Discriminator:0.38939541578292847\n",
      "Epoch:4\n",
      "Loss Generator:2.2032485008239746\n",
      "Loss Discriminator:0.3691960573196411\n",
      "Epoch:4\n",
      "Loss Generator:1.7295275926589966\n",
      "Loss Discriminator:0.40972045063972473\n",
      "Epoch:4\n",
      "Loss Generator:1.2629594802856445\n",
      "Loss Discriminator:0.541883647441864\n",
      "Epoch:4\n",
      "Loss Generator:2.2045648097991943\n",
      "Loss Discriminator:0.44473129510879517\n",
      "Epoch:4\n",
      "Loss Generator:2.2859225273132324\n",
      "Loss Discriminator:0.3586997389793396\n",
      "Epoch:4\n",
      "Loss Generator:1.0842853784561157\n",
      "Loss Discriminator:0.44888854026794434\n",
      "Epoch:4\n",
      "Loss Generator:0.6735804080963135\n",
      "Loss Discriminator:0.5642111897468567\n",
      "Epoch:4\n",
      "Loss Generator:1.372110366821289\n",
      "Loss Discriminator:0.3935924172401428\n",
      "Epoch:4\n",
      "Loss Generator:1.5786573886871338\n",
      "Loss Discriminator:0.4056338667869568\n",
      "Epoch:4\n",
      "Loss Generator:1.1762542724609375\n",
      "Loss Discriminator:0.44159403443336487\n",
      "Epoch:4\n",
      "Loss Generator:1.9345347881317139\n",
      "Loss Discriminator:0.4090860188007355\n",
      "Epoch:4\n",
      "Loss Generator:2.3529438972473145\n",
      "Loss Discriminator:0.383417010307312\n",
      "Epoch:4\n",
      "Loss Generator:2.4423561096191406\n",
      "Loss Discriminator:0.38229966163635254\n",
      "Epoch:4\n",
      "Loss Generator:3.0838165283203125\n",
      "Loss Discriminator:0.4243182837963104\n",
      "Epoch:4\n",
      "Loss Generator:2.554776191711426\n",
      "Loss Discriminator:0.37047508358955383\n",
      "Epoch:4\n",
      "Loss Generator:2.7504053115844727\n",
      "Loss Discriminator:0.4388808608055115\n",
      "Epoch:5\n",
      "Loss Generator:1.121781349182129\n",
      "Loss Discriminator:0.42255765199661255\n",
      "Epoch:5\n",
      "Loss Generator:2.6043872833251953\n",
      "Loss Discriminator:0.37880146503448486\n",
      "Epoch:5\n",
      "Loss Generator:2.6047470569610596\n",
      "Loss Discriminator:0.37911874055862427\n",
      "Epoch:5\n",
      "Loss Generator:1.7878907918930054\n",
      "Loss Discriminator:0.4064199924468994\n",
      "Epoch:5\n",
      "Loss Generator:1.4976943731307983\n",
      "Loss Discriminator:0.3899368941783905\n",
      "Epoch:5\n",
      "Loss Generator:1.2338824272155762\n",
      "Loss Discriminator:0.41350850462913513\n",
      "Epoch:5\n",
      "Loss Generator:2.291515350341797\n",
      "Loss Discriminator:0.42632296681404114\n",
      "Epoch:5\n",
      "Loss Generator:2.75420880317688\n",
      "Loss Discriminator:0.39426931738853455\n",
      "Epoch:5\n",
      "Loss Generator:1.9593253135681152\n",
      "Loss Discriminator:0.38584935665130615\n",
      "Epoch:5\n",
      "Loss Generator:1.8581864833831787\n",
      "Loss Discriminator:0.41081923246383667\n",
      "Epoch:5\n",
      "Loss Generator:1.070979356765747\n",
      "Loss Discriminator:0.4586319625377655\n",
      "Epoch:5\n",
      "Loss Generator:2.5380921363830566\n",
      "Loss Discriminator:0.39919692277908325\n",
      "Epoch:5\n",
      "Loss Generator:2.433558464050293\n",
      "Loss Discriminator:0.4008159637451172\n",
      "Epoch:5\n",
      "Loss Generator:2.626004219055176\n",
      "Loss Discriminator:0.3681996464729309\n",
      "Epoch:5\n",
      "Loss Generator:2.1750783920288086\n",
      "Loss Discriminator:0.35808807611465454\n",
      "Epoch:5\n",
      "Loss Generator:1.6577727794647217\n",
      "Loss Discriminator:0.4132925271987915\n",
      "Epoch:5\n",
      "Loss Generator:4.2973809242248535\n",
      "Loss Discriminator:0.6593539714813232\n",
      "Epoch:5\n",
      "Loss Generator:1.9832721948623657\n",
      "Loss Discriminator:0.3669350743293762\n",
      "Epoch:5\n",
      "Loss Generator:0.9153002500534058\n",
      "Loss Discriminator:0.40874266624450684\n",
      "Epoch:5\n",
      "Loss Generator:2.127739667892456\n",
      "Loss Discriminator:0.37839412689208984\n",
      "Epoch:5\n",
      "Loss Generator:1.338069200515747\n",
      "Loss Discriminator:0.6759882569313049\n",
      "Epoch:5\n",
      "Loss Generator:2.4615211486816406\n",
      "Loss Discriminator:0.3484296202659607\n",
      "Epoch:5\n",
      "Loss Generator:1.2335188388824463\n",
      "Loss Discriminator:0.4571748971939087\n",
      "Epoch:5\n",
      "Loss Generator:2.4141860008239746\n",
      "Loss Discriminator:0.3728250563144684\n",
      "Epoch:5\n",
      "Loss Generator:2.2492926120758057\n",
      "Loss Discriminator:0.36943519115448\n",
      "Epoch:5\n",
      "Loss Generator:1.2393925189971924\n",
      "Loss Discriminator:0.4967234134674072\n",
      "Epoch:5\n",
      "Loss Generator:1.318708896636963\n",
      "Loss Discriminator:0.5174586772918701\n",
      "Epoch:5\n",
      "Loss Generator:2.6726341247558594\n",
      "Loss Discriminator:0.3648960590362549\n",
      "Epoch:5\n",
      "Loss Generator:2.2291195392608643\n",
      "Loss Discriminator:0.3668805658817291\n",
      "Epoch:5\n",
      "Loss Generator:1.2944971323013306\n",
      "Loss Discriminator:0.5269924402236938\n",
      "Epoch:5\n",
      "Loss Generator:2.5723791122436523\n",
      "Loss Discriminator:0.3667795956134796\n",
      "Epoch:5\n",
      "Loss Generator:1.4989826679229736\n",
      "Loss Discriminator:0.364060640335083\n",
      "Epoch:6\n",
      "Loss Generator:2.801722526550293\n",
      "Loss Discriminator:0.494235634803772\n",
      "Epoch:6\n",
      "Loss Generator:4.401957035064697\n",
      "Loss Discriminator:0.6937022805213928\n",
      "Epoch:6\n",
      "Loss Generator:3.341278076171875\n",
      "Loss Discriminator:0.43596863746643066\n",
      "Epoch:6\n",
      "Loss Generator:3.042093276977539\n",
      "Loss Discriminator:0.4249776303768158\n",
      "Epoch:6\n",
      "Loss Generator:1.1114305257797241\n",
      "Loss Discriminator:0.45804235339164734\n",
      "Epoch:6\n",
      "Loss Generator:5.3510870933532715\n",
      "Loss Discriminator:0.950491726398468\n",
      "Epoch:6\n",
      "Loss Generator:2.5602822303771973\n",
      "Loss Discriminator:0.353771448135376\n",
      "Epoch:6\n",
      "Loss Generator:2.2979624271392822\n",
      "Loss Discriminator:0.38183775544166565\n",
      "Epoch:6\n",
      "Loss Generator:2.3545637130737305\n",
      "Loss Discriminator:0.3544044494628906\n",
      "Epoch:6\n",
      "Loss Generator:1.5421885251998901\n",
      "Loss Discriminator:0.36588066816329956\n",
      "Epoch:6\n",
      "Loss Generator:2.5361316204071045\n",
      "Loss Discriminator:0.34739750623703003\n",
      "Epoch:6\n",
      "Loss Generator:2.2246742248535156\n",
      "Loss Discriminator:0.3484959602355957\n",
      "Epoch:6\n",
      "Loss Generator:2.1900274753570557\n",
      "Loss Discriminator:0.35516130924224854\n",
      "Epoch:6\n",
      "Loss Generator:2.4007408618927\n",
      "Loss Discriminator:0.3480234146118164\n",
      "Epoch:6\n",
      "Loss Generator:2.450316905975342\n",
      "Loss Discriminator:0.35223156213760376\n",
      "Epoch:6\n",
      "Loss Generator:2.093743324279785\n",
      "Loss Discriminator:0.467833548784256\n",
      "Epoch:6\n",
      "Loss Generator:2.2168638706207275\n",
      "Loss Discriminator:0.36902421712875366\n",
      "Epoch:6\n",
      "Loss Generator:1.4406964778900146\n",
      "Loss Discriminator:0.3748186528682709\n",
      "Epoch:6\n",
      "Loss Generator:2.557093381881714\n",
      "Loss Discriminator:0.40413081645965576\n",
      "Epoch:6\n",
      "Loss Generator:0.8681137561798096\n",
      "Loss Discriminator:0.5556023716926575\n",
      "Epoch:6\n",
      "Loss Generator:2.1983425617218018\n",
      "Loss Discriminator:0.37204283475875854\n",
      "Epoch:6\n",
      "Loss Generator:2.821718454360962\n",
      "Loss Discriminator:0.3877493143081665\n",
      "Epoch:6\n",
      "Loss Generator:3.7687931060791016\n",
      "Loss Discriminator:0.6177623271942139\n",
      "Epoch:6\n",
      "Loss Generator:2.308910608291626\n",
      "Loss Discriminator:0.3375939726829529\n",
      "Epoch:6\n",
      "Loss Generator:2.6512250900268555\n",
      "Loss Discriminator:0.37043216824531555\n",
      "Epoch:6\n",
      "Loss Generator:1.8174482583999634\n",
      "Loss Discriminator:0.3865879774093628\n",
      "Epoch:6\n",
      "Loss Generator:2.618579864501953\n",
      "Loss Discriminator:0.3871424198150635\n",
      "Epoch:6\n",
      "Loss Generator:4.6216583251953125\n",
      "Loss Discriminator:0.6591719388961792\n",
      "Epoch:6\n",
      "Loss Generator:2.63553524017334\n",
      "Loss Discriminator:0.4110304117202759\n",
      "Epoch:6\n",
      "Loss Generator:1.2789249420166016\n",
      "Loss Discriminator:0.4017057418823242\n",
      "Epoch:6\n",
      "Loss Generator:2.068643569946289\n",
      "Loss Discriminator:0.3566843271255493\n",
      "Epoch:6\n",
      "Loss Generator:1.6874332427978516\n",
      "Loss Discriminator:0.363972544670105\n",
      "Epoch:7\n",
      "Loss Generator:2.2046735286712646\n",
      "Loss Discriminator:0.41639789938926697\n",
      "Epoch:7\n",
      "Loss Generator:2.630506753921509\n",
      "Loss Discriminator:0.363677054643631\n",
      "Epoch:7\n",
      "Loss Generator:2.1121597290039062\n",
      "Loss Discriminator:0.3705941438674927\n",
      "Epoch:7\n",
      "Loss Generator:1.9510040283203125\n",
      "Loss Discriminator:0.4563685655593872\n",
      "Epoch:7\n",
      "Loss Generator:2.1230273246765137\n",
      "Loss Discriminator:0.35684749484062195\n",
      "Epoch:7\n",
      "Loss Generator:2.6981618404388428\n",
      "Loss Discriminator:0.37724512815475464\n",
      "Epoch:7\n",
      "Loss Generator:2.358417272567749\n",
      "Loss Discriminator:0.34788718819618225\n",
      "Epoch:7\n",
      "Loss Generator:2.3819029331207275\n",
      "Loss Discriminator:0.3619789779186249\n",
      "Epoch:7\n",
      "Loss Generator:2.6405816078186035\n",
      "Loss Discriminator:0.3673126697540283\n",
      "Epoch:7\n",
      "Loss Generator:2.046417474746704\n",
      "Loss Discriminator:0.3944426476955414\n",
      "Epoch:7\n",
      "Loss Generator:2.586458444595337\n",
      "Loss Discriminator:0.35161757469177246\n",
      "Epoch:7\n",
      "Loss Generator:3.363054037094116\n",
      "Loss Discriminator:0.42747586965560913\n",
      "Epoch:7\n",
      "Loss Generator:3.2122011184692383\n",
      "Loss Discriminator:0.4494537115097046\n",
      "Epoch:7\n",
      "Loss Generator:1.5795724391937256\n",
      "Loss Discriminator:0.4656229019165039\n",
      "Epoch:7\n",
      "Loss Generator:2.368197202682495\n",
      "Loss Discriminator:0.34754446148872375\n",
      "Epoch:7\n",
      "Loss Generator:1.9542897939682007\n",
      "Loss Discriminator:0.3729938268661499\n",
      "Epoch:7\n",
      "Loss Generator:2.1498074531555176\n",
      "Loss Discriminator:0.3792310357093811\n",
      "Epoch:7\n",
      "Loss Generator:2.028921365737915\n",
      "Loss Discriminator:0.358908474445343\n",
      "Epoch:7\n",
      "Loss Generator:2.591155529022217\n",
      "Loss Discriminator:0.3569030463695526\n",
      "Epoch:7\n",
      "Loss Generator:1.3381142616271973\n",
      "Loss Discriminator:0.3937138319015503\n",
      "Epoch:7\n",
      "Loss Generator:3.199007511138916\n",
      "Loss Discriminator:0.37421315908432007\n",
      "Epoch:7\n",
      "Loss Generator:2.375598907470703\n",
      "Loss Discriminator:0.35841259360313416\n",
      "Epoch:7\n",
      "Loss Generator:2.0101583003997803\n",
      "Loss Discriminator:0.36425384879112244\n",
      "Epoch:7\n",
      "Loss Generator:1.758925199508667\n",
      "Loss Discriminator:0.36710983514785767\n",
      "Epoch:7\n",
      "Loss Generator:1.9228330850601196\n",
      "Loss Discriminator:0.3855552673339844\n",
      "Epoch:7\n",
      "Loss Generator:2.1050524711608887\n",
      "Loss Discriminator:0.35660457611083984\n",
      "Epoch:7\n",
      "Loss Generator:1.9114410877227783\n",
      "Loss Discriminator:0.388458788394928\n",
      "Epoch:7\n",
      "Loss Generator:2.8992409706115723\n",
      "Loss Discriminator:0.383486270904541\n",
      "Epoch:7\n",
      "Loss Generator:1.4932167530059814\n",
      "Loss Discriminator:0.4086247682571411\n",
      "Epoch:7\n",
      "Loss Generator:2.601907730102539\n",
      "Loss Discriminator:0.3521643877029419\n",
      "Epoch:7\n",
      "Loss Generator:2.3623313903808594\n",
      "Loss Discriminator:0.3562218248844147\n",
      "Epoch:7\n",
      "Loss Generator:2.5695888996124268\n",
      "Loss Discriminator:0.3638014793395996\n",
      "Epoch:8\n",
      "Loss Generator:0.8156319260597229\n",
      "Loss Discriminator:0.7378509640693665\n",
      "Epoch:8\n",
      "Loss Generator:2.0858731269836426\n",
      "Loss Discriminator:0.35871511697769165\n",
      "Epoch:8\n",
      "Loss Generator:2.7654433250427246\n",
      "Loss Discriminator:0.40693458914756775\n",
      "Epoch:8\n",
      "Loss Generator:2.323627471923828\n",
      "Loss Discriminator:0.3463290333747864\n",
      "Epoch:8\n",
      "Loss Generator:3.009547710418701\n",
      "Loss Discriminator:0.3565857708454132\n",
      "Epoch:8\n",
      "Loss Generator:3.888157367706299\n",
      "Loss Discriminator:0.40567129850387573\n",
      "Epoch:8\n",
      "Loss Generator:2.5830891132354736\n",
      "Loss Discriminator:0.3879755437374115\n",
      "Epoch:8\n",
      "Loss Generator:1.6693694591522217\n",
      "Loss Discriminator:0.34719839692115784\n",
      "Epoch:8\n",
      "Loss Generator:3.031421661376953\n",
      "Loss Discriminator:0.3834872841835022\n",
      "Epoch:8\n",
      "Loss Generator:1.4271875619888306\n",
      "Loss Discriminator:0.39558491110801697\n",
      "Epoch:8\n",
      "Loss Generator:2.3437299728393555\n",
      "Loss Discriminator:0.3459642827510834\n",
      "Epoch:8\n",
      "Loss Generator:2.5205464363098145\n",
      "Loss Discriminator:0.3696979284286499\n",
      "Epoch:8\n",
      "Loss Generator:2.047179937362671\n",
      "Loss Discriminator:0.35958272218704224\n",
      "Epoch:8\n",
      "Loss Generator:1.1878986358642578\n",
      "Loss Discriminator:0.4730404317378998\n",
      "Epoch:8\n",
      "Loss Generator:1.5311999320983887\n",
      "Loss Discriminator:0.3984266519546509\n",
      "Epoch:8\n",
      "Loss Generator:0.45686954259872437\n",
      "Loss Discriminator:0.7177756428718567\n",
      "Epoch:8\n",
      "Loss Generator:1.927596926689148\n",
      "Loss Discriminator:0.36039263010025024\n",
      "Epoch:8\n",
      "Loss Generator:2.449765205383301\n",
      "Loss Discriminator:0.34829193353652954\n",
      "Epoch:8\n",
      "Loss Generator:2.317976951599121\n",
      "Loss Discriminator:0.35780030488967896\n",
      "Epoch:8\n",
      "Loss Generator:2.6043641567230225\n",
      "Loss Discriminator:0.3925785422325134\n",
      "Epoch:8\n",
      "Loss Generator:3.8086886405944824\n",
      "Loss Discriminator:0.4609379470348358\n",
      "Epoch:8\n",
      "Loss Generator:2.1027894020080566\n",
      "Loss Discriminator:0.3681100010871887\n",
      "Epoch:8\n",
      "Loss Generator:1.949387550354004\n",
      "Loss Discriminator:0.36579859256744385\n",
      "Epoch:8\n",
      "Loss Generator:2.306426525115967\n",
      "Loss Discriminator:0.34865814447402954\n",
      "Epoch:8\n",
      "Loss Generator:2.912224054336548\n",
      "Loss Discriminator:0.3485296666622162\n",
      "Epoch:8\n",
      "Loss Generator:1.890600323677063\n",
      "Loss Discriminator:0.35697346925735474\n",
      "Epoch:8\n",
      "Loss Generator:2.1250483989715576\n",
      "Loss Discriminator:0.3429046869277954\n",
      "Epoch:8\n",
      "Loss Generator:1.7294292449951172\n",
      "Loss Discriminator:0.370402991771698\n",
      "Epoch:8\n",
      "Loss Generator:2.2579612731933594\n",
      "Loss Discriminator:0.35865989327430725\n",
      "Epoch:8\n",
      "Loss Generator:2.623358964920044\n",
      "Loss Discriminator:0.35737666487693787\n",
      "Epoch:8\n",
      "Loss Generator:2.3199305534362793\n",
      "Loss Discriminator:0.36541587114334106\n",
      "Epoch:8\n",
      "Loss Generator:1.3186793327331543\n",
      "Loss Discriminator:0.40242999792099\n",
      "Epoch:9\n",
      "Loss Generator:2.864713668823242\n",
      "Loss Discriminator:0.3944516181945801\n",
      "Epoch:9\n",
      "Loss Generator:3.9578778743743896\n",
      "Loss Discriminator:0.46986037492752075\n",
      "Epoch:9\n",
      "Loss Generator:2.251051187515259\n",
      "Loss Discriminator:0.3413432836532593\n",
      "Epoch:9\n",
      "Loss Generator:2.991607427597046\n",
      "Loss Discriminator:0.4841609597206116\n",
      "Epoch:9\n",
      "Loss Generator:2.359804153442383\n",
      "Loss Discriminator:0.3588319420814514\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[89]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epochs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m20\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx,(real,_) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[32m      3\u001b[39m         real=real.to(device)\n\u001b[32m      4\u001b[39m         noise=torch.randn((batch_size,z_dim,\u001b[32m1\u001b[39m,\u001b[32m1\u001b[39m)).to(device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nichu\\.conda\\envs\\jupytorch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28mself\u001b[39m._next_data()\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nichu\\.conda\\envs\\jupytorch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1491\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1488\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data, worker_id)\n\u001b[32m   1490\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1491\u001b[39m idx, data = \u001b[38;5;28mself\u001b[39m._get_data()\n\u001b[32m   1492\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1494\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nichu\\.conda\\envs\\jupytorch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1453\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1449\u001b[39m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[32m   1450\u001b[39m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[32m   1451\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1452\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1453\u001b[39m         success, data = \u001b[38;5;28mself\u001b[39m._try_get_data()\n\u001b[32m   1454\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1455\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nichu\\.conda\\envs\\jupytorch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1284\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1271\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=_utils.MP_STATUS_CHECK_INTERVAL):\n\u001b[32m   1272\u001b[39m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[32m   1273\u001b[39m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1281\u001b[39m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[32m   1282\u001b[39m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[32m   1283\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1284\u001b[39m         data = \u001b[38;5;28mself\u001b[39m._data_queue.get(timeout=timeout)\n\u001b[32m   1285\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[32m   1286\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1287\u001b[39m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[32m   1288\u001b[39m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[32m   1289\u001b[39m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nichu\\.conda\\envs\\jupytorch\\Lib\\multiprocessing\\queues.py:113\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[32m    112\u001b[39m     timeout = deadline - time.monotonic()\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._poll(timeout):\n\u001b[32m    114\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._poll():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nichu\\.conda\\envs\\jupytorch\\Lib\\multiprocessing\\connection.py:257\u001b[39m, in \u001b[36m_ConnectionBase.poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    255\u001b[39m \u001b[38;5;28mself\u001b[39m._check_closed()\n\u001b[32m    256\u001b[39m \u001b[38;5;28mself\u001b[39m._check_readable()\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._poll(timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nichu\\.conda\\envs\\jupytorch\\Lib\\multiprocessing\\connection.py:346\u001b[39m, in \u001b[36mPipeConnection._poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._got_empty_message \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m    344\u001b[39m             _winapi.PeekNamedPipe(\u001b[38;5;28mself\u001b[39m._handle)[\u001b[32m0\u001b[39m] != \u001b[32m0\u001b[39m):\n\u001b[32m    345\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(wait([\u001b[38;5;28mself\u001b[39m], timeout))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nichu\\.conda\\envs\\jupytorch\\Lib\\multiprocessing\\connection.py:896\u001b[39m, in \u001b[36mwait\u001b[39m\u001b[34m(object_list, timeout)\u001b[39m\n\u001b[32m    893\u001b[39m                 ready_objects.add(o)\n\u001b[32m    894\u001b[39m                 timeout = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m896\u001b[39m     ready_handles = _exhaustive_wait(waithandle_to_obj.keys(), timeout)\n\u001b[32m    897\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    898\u001b[39m     \u001b[38;5;66;03m# request that overlapped reads stop\u001b[39;00m\n\u001b[32m    899\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m ov \u001b[38;5;129;01min\u001b[39;00m ov_list:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nichu\\.conda\\envs\\jupytorch\\Lib\\multiprocessing\\connection.py:828\u001b[39m, in \u001b[36m_exhaustive_wait\u001b[39m\u001b[34m(handles, timeout)\u001b[39m\n\u001b[32m    826\u001b[39m ready = []\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m L:\n\u001b[32m--> \u001b[39m\u001b[32m828\u001b[39m     res = _winapi.WaitForMultipleObjects(L, \u001b[38;5;28;01mFalse\u001b[39;00m, timeout)\n\u001b[32m    829\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m res == WAIT_TIMEOUT:\n\u001b[32m    830\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for epochs in range(20):\n",
    "    for batch_idx,(real,_) in enumerate(loader):\n",
    "        real=real.to(device)\n",
    "        noise=torch.randn((batch_size,z_dim,1,1)).to(device)\n",
    "        fake=gen(noise)\n",
    "\n",
    "        disc_real=disc(real).reshape(-1)\n",
    "        real_labels=torch.full_like(disc_real,0.9)\n",
    "        lossD_real=criterion(disc_real,real_labels)\n",
    "        disc_fake=disc(fake.detach()).reshape(-1)\n",
    "        fake_labels=torch.full_like(disc_fake,0.1)\n",
    "        lossD_fake=criterion(disc_fake,fake_labels)\n",
    "        lossD=(lossD_fake+lossD_real)/2\n",
    "        disc.zero_grad()\n",
    "        lossD.backward()\n",
    "        opt_disc.step()\n",
    "\n",
    "        output=disc(fake).reshape(-1)\n",
    "        lossG=criterion(output,torch.ones_like(output))\n",
    "        gen.zero_grad()\n",
    "        lossG.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        if batch_idx%100==0:\n",
    "            print(f\"Epoch:{epochs}\\nLoss Generator:{lossG}\\nLoss Discriminator:{lossD}\")\n",
    "            with torch.no_grad():\n",
    "                fake=gen(fixed_noise)\n",
    "                img_grid_fake=torchvision.utils.make_grid(fake[:32],normalize=True)\n",
    "                img_grid_real=torchvision.utils.make_grid(real[:32],normalize=True)\n",
    "                writer_fake.add_image(\"Fake\",img_grid_fake,global_step=step)\n",
    "                writer_real.add_image(\"Real\",img_grid_real,global_step=step)\n",
    "        step+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupytorch",
   "language": "python",
   "name": "jupytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
