{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "97c2b2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "46ea8732",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,img_dim):\n",
    "        super().__init__()\n",
    "        self.disc=nn.Sequential(\n",
    "            nn.Linear(img_dim,128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(128,1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.disc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "587f362a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, img_dim):\n",
    "        super().__init__()\n",
    "        self.gen=nn.Sequential(\n",
    "            nn.Linear(z_dim,256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256,img_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.gen(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2789f287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device=\"cuda\" if torch.cuda.is_available else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "11171207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0003"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr=3e-4\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "557ab0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim=64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d17240",
   "metadata": {},
   "source": [
    "My understanding of latent space is that the numbers of xertian number of dimensions are passed ike 64 dimensions. the neural network\n",
    "updates the weights in itself to produce images from these latent space. when the training is fully good you can move around the latent space to produce images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "52410a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dim=28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5970e131",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "epochs=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4b9bffa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc=Discriminator(img_dim=img_dim).to(device)\n",
    "gen=Generator(z_dim=z_dim,img_dim=img_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c367b34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_noise=torch.randn((batch_size,z_dim)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e10b23eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=0.5,std=0.5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "db7c5404",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=datasets.MNIST(root='data/',transform=transform,download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f96a0e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=DataLoader(dataset=dataset,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5a8515f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_disc=optim.Adam(disc.parameters(),lr=lr)\n",
    "opt_gen=optim.Adam(gen.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "47b00a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "06a3f758",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_fake=SummaryWriter(f\"runs/GAN_MNIST/fake\")\n",
    "writer_real=SummaryWriter(f\"runs/GAN_MNIST/real\")\n",
    "step=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4b02f4",
   "metadata": {},
   "source": [
    "D(real) discriminators prediction on real image- it wants 1 \n",
    "g(z) image generated from noise by the generator\n",
    "D(g(z)) discriminators prediction on fake imgae it wants 0\n",
    "\n",
    "\n",
    "L=−[y⋅log(p)+(1−y)⋅log(1−p)] BCE loss\n",
    "\n",
    "with torches.oneslike 1-y makes it zero you are left with -logp\n",
    "y is the ones like or zeroes like \n",
    "you get log(1-p)\n",
    "\n",
    "disc real is D(real)\n",
    "disc fake is D(g(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "da3f5f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Loss Generator:1.181633710861206\n",
      " Loss Discriminator:0.5205905437469482\n",
      "2\n",
      "Loss Generator:0.9782984256744385\n",
      " Loss Discriminator:0.5327741503715515\n",
      "3\n",
      "Loss Generator:1.2214889526367188\n",
      " Loss Discriminator:0.5596961379051208\n",
      "4\n",
      "Loss Generator:1.2432044744491577\n",
      " Loss Discriminator:0.5784693360328674\n",
      "5\n",
      "Loss Generator:1.1513179540634155\n",
      " Loss Discriminator:0.5754204392433167\n",
      "6\n",
      "Loss Generator:1.1876444816589355\n",
      " Loss Discriminator:0.6705034971237183\n",
      "7\n",
      "Loss Generator:1.2364444732666016\n",
      " Loss Discriminator:0.7147685289382935\n",
      "8\n",
      "Loss Generator:0.9844697117805481\n",
      " Loss Discriminator:0.5824205875396729\n",
      "9\n",
      "Loss Generator:1.0112885236740112\n",
      " Loss Discriminator:0.7141392827033997\n",
      "10\n",
      "Loss Generator:1.198325514793396\n",
      " Loss Discriminator:0.5414620637893677\n",
      "11\n",
      "Loss Generator:0.8715474009513855\n",
      " Loss Discriminator:0.6740407943725586\n",
      "12\n",
      "Loss Generator:0.9233049750328064\n",
      " Loss Discriminator:0.6600501537322998\n",
      "13\n",
      "Loss Generator:1.068987488746643\n",
      " Loss Discriminator:0.581080436706543\n",
      "14\n",
      "Loss Generator:0.9370893239974976\n",
      " Loss Discriminator:0.6081804037094116\n",
      "15\n",
      "Loss Generator:0.8075716495513916\n",
      " Loss Discriminator:0.7020859718322754\n",
      "16\n",
      "Loss Generator:1.0483341217041016\n",
      " Loss Discriminator:0.6495530605316162\n",
      "17\n",
      "Loss Generator:1.1111750602722168\n",
      " Loss Discriminator:0.6098349690437317\n",
      "18\n",
      "Loss Generator:0.8279025554656982\n",
      " Loss Discriminator:0.6434946060180664\n",
      "19\n",
      "Loss Generator:0.7530776858329773\n",
      " Loss Discriminator:0.6132740378379822\n",
      "20\n",
      "Loss Generator:0.8236202597618103\n",
      " Loss Discriminator:0.668356716632843\n",
      "21\n",
      "Loss Generator:0.9075985550880432\n",
      " Loss Discriminator:0.6486344933509827\n",
      "22\n",
      "Loss Generator:0.9127663373947144\n",
      " Loss Discriminator:0.6626906394958496\n",
      "23\n",
      "Loss Generator:0.7909433841705322\n",
      " Loss Discriminator:0.6972687244415283\n"
     ]
    }
   ],
   "source": [
    "for epochs in range(epochs):\n",
    "    for batch_idx,(real,_) in enumerate(loader):\n",
    "        real=real.view(-1,784).to(device)\n",
    "        batch_size=real.shape[0]\n",
    "\n",
    "        ##Train discrimintator :max log(D(real)) + log(1-D(G(z)))\n",
    "        noise=torch.randn(batch_size,z_dim).to(device)\n",
    "        fake=gen(noise)\n",
    "        disc_real=disc(real).view(-1)#squashes them into 1d\n",
    "        lossD_real=criterion(disc_real,torch.ones_like(disc_real))#max log(D(real)) trying to get this\n",
    "        disc_fake=disc(fake).view(-1)\n",
    "        lossD_fake=criterion(disc_fake,torch.zeros_like(disc_fake))# log(1-D(G(z)) trying to get this\n",
    "        lossD=(lossD_fake+lossD_real)/2 #averaging\n",
    "        disc.zero_grad()\n",
    "        lossD.backward(retain_graph=True)#when you do this it cleares all the cache like in fake is cleared everything\n",
    "        #compututaional grpah is the graph of the formulas\n",
    "        opt_disc.step()\n",
    "\n",
    "        #train Generator minlog(1-D(G(z))) this lead to vanishing gradients so we max(log(d(g(z))))\n",
    "        output=disc(fake).view(-1)\n",
    "        lossG=criterion(output,torch.ones_like(output))\n",
    "        gen.zero_grad()\n",
    "        lossG.backward()#get the gradients\n",
    "        opt_gen.step()#update teh discriminators weights\n",
    "\n",
    "        if batch_idx==0:\n",
    "            print(f\"{epochs+1}\")\n",
    "            print(f\"Loss Generator:{lossG}\\n Loss Discriminator:{lossD}\")\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fake=gen(fixed_noise).reshape(-1,1,28,28)\n",
    "                data=real.reshape(-1,1,28,28)\n",
    "                img_grid_fake=torchvision.utils.make_grid(fake,normalize=True)\n",
    "                img_grid_real=torchvision.utils.make_grid(data,normalize=True)\n",
    "                writer_fake.add_image(\n",
    "                    \"MNIST Fake image\",img_grid_fake,global_step=step\n",
    "                )\n",
    "                writer_real.add_image(\n",
    "                    \"MNIST Real image\",img_grid_real,global_step=step\n",
    "                )\n",
    "                writer_real.flush()\n",
    "                writer_fake.flush()\n",
    "                step+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupytorch",
   "language": "python",
   "name": "jupytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
